packaging==23.2
torch==2.1.2
vllm==0.2.7
bitsandbytes==0.42.0
datasets==2.16.1
deepspeed==0.13.1
evaluate==0.4.1
# flash-attn==2.0.4
fschat==0.2.35
hydra-core==1.0.7
ninja==1.11.1.1
numpy==1.26.3
pandas==2.2.0
requests==2.27.1
scikit-learn==1.4.0
scipy==1.12.0
sentencepiece==0.1.99
tiktoken==0.6.0
tokenizers==0.19.1
tqdm==4.66.1
transformers==4.41.2
wandb==0.16.2
xformers==0.0.23.post1
openai==1.76.0
python-dotenv==1.1.0
